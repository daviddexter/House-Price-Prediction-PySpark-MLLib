{"cells":[{"cell_type":"markdown","source":["## House Price Prediction using Linear Regression Model (PySpark & MLLib)\nThis is an attempt to use Linear Prediction to predict the price of houses from a test data set for the city of Sacramento.\nThe data file has attributes like street, city, zip, state, beds, baths, sq__ft, type, sale_date, price, latitude, longitude."],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql import Row"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["## Data Loading\nWe get the file using wget command. The file has been uploaded to dropbox for easy access."],"metadata":{}},{"cell_type":"code","source":["%sh\nwget 'https://www.dropbox.com/s/a6l14d0ngrk7x2i/Sacramentorealestatetransactions.csv?dl=0' -O houses_data.csv\n\nhouses_data = spark.read\\\n  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n  .option('header', 'true')\\\n  .option('inferSchema', 'true')\\\n  .load(\"file:/databricks/driver/houses_data.csv\")\n#houses = sqlContext.read.format('csv').options(header='true', inferSchema='true').load('/FileStore/tables/Sacramentorealestatetransactions.csv')"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["Here, we take a look at the data present in the CSV file"],"metadata":{}},{"cell_type":"code","source":["rdd = sc.textFile('file:/databricks/driver/houses_data.csv')\nrdd.take(5)\n"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["The following step maps the RDD by splitting the lines which are ',' delimited and convert them to RDD's tuple format."],"metadata":{}},{"cell_type":"code","source":["rdd = rdd.map(lambda line: line.split(\",\"))\nrdd.take(2)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["Next, we use the 'filter' transformation to remove any lines which contain headers, from the RDD."],"metadata":{}},{"cell_type":"code","source":["header = rdd.first()\nrdd = rdd.filter(lambda line:line != header)\nrdd.take(2)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Converting the RDD to DataFrame"],"metadata":{}},{"cell_type":"code","source":["df = rdd.map(lambda line: Row(street = line[0], city = line[1], zip=line[2], beds=line[4], baths=line[5], sqft=line[6], price=line[9])).toDF()\ndf.show()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["df.toPandas().head()"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["In Cmd 15, we group the data on the number of beds and count the houses based on that data. We notice that there are 108 houses with '0' beds which is offcourse, not possible."],"metadata":{}},{"cell_type":"code","source":["df.groupBy(\"beds\").count().show()"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["df.describe(['baths', 'beds','price','sqft']).show()"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Importing necessary modules for Linear Regression"],"metadata":{}},{"cell_type":"code","source":["import pyspark.mllib\nimport pyspark.mllib.regression\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.sql.functions import *"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["We start by creating a dataframe df that has only the subset of features we're interested in. We're going to predict the price of the house from the number of baths, beds, and square feet."],"metadata":{}},{"cell_type":"code","source":["df = df.select('price','baths','beds','sqft')"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["Here, we exclude all suspicious values from the dataframe for any of the features we are using for prediction."],"metadata":{}},{"cell_type":"code","source":["df = df[df.baths > 0]\ndf = df[df.beds > 0]\ndf = df[df.sqft > 0]\ndf.describe(['baths','beds','price','sqft']).show()"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":["## Labeled Points\nThe features should be expressed with LabeledPoints. The required format for a labeled point is a tuple of the response value and a vector of predictors. We can call 'map' on df in order to return an RDD of LabeledPoints."],"metadata":{}},{"cell_type":"code","source":["temp = df.rdd.map(lambda line:LabeledPoint(line[0],[line[1:]]))\ntemp.take(5)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["## Data Scaling\nWe are using Stochastic Gradient Descent and the square footage of the houses is quite large in comparison to the number of bedrooms and bathrooms. Hence, we use the StandardScaler to scale required data for easy calculations and metrics."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.util import MLUtils\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.mllib.feature import StandardScaler"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["features = df.rdd.map(lambda row: row[1:])\nfeatures.take(5)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["standardizer = StandardScaler()\nmodel = standardizer.fit(features)\nfeatures_transform = model.transform(features)\nfeatures_transform.take(5)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["## Labels with features\nThe labels (prices) are in a DataFrame and the scaled features are in the new RDD we created.\nWe map the RDD which gets all the prices (zero elements) from each row."],"metadata":{}},{"cell_type":"code","source":["lab = df.rdd.map(lambda row: row[0])\nlab.take(5)"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["transformedData = lab.zip(features_transform)\ntransformedData.take(5)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["transformedData = transformedData.map(lambda row: LabeledPoint(row[0],[row[1]]))\ntransformedData.take(5)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["Splitting the datasets into training and testing datasets"],"metadata":{}},{"cell_type":"code","source":["trainingData, testingData = transformedData.randomSplit([.8,.2],seed=1234)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":["Importing linear regression with stochastic gradient descent and building a model. The number of iterations is specified along with the step size and the data set."],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.regression import LinearRegressionWithSGD\nlinearModel = LinearRegressionWithSGD.train(trainingData,1000,.2)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["Now we can pull features such as coefficients and intercepts from the model."],"metadata":{}},{"cell_type":"code","source":["linearModel.weights"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["We are showing the first 10 points from the test set. We can make a prediction on one of the points using our model."],"metadata":{}},{"cell_type":"code","source":["testingData.take(10)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["## Prediction on one data point from the test dataset\nOutput is the projected price of the house in USD."],"metadata":{}},{"cell_type":"code","source":["linearModel.predict([1.49297445326,3.52055958053,1.73535287287])"],"metadata":{},"outputs":[],"execution_count":42}],"metadata":{"name":"House Price Prediction","notebookId":3829675626048790},"nbformat":4,"nbformat_minor":0}
